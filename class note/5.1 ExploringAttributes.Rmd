---
title: "Exploring sample attributes"
subtitle: "Transformations and model summaries"
author: |
  | R.W. Oldford
graphics: yes
output:
  beamer_presentation: 
    theme: "default"
    colortheme: "sidebartab"
    fonttheme: "structureitalicserif"
  ioslides_presentation:
    incremental: true
    widescreen: true
  slidy_presentation: 
    incremental: true
slide_level: 3
fontsize: 9pt
urlcolor: blue
header-includes:
- \usepackage{graphicx}
- \usepackage{epic}
- \usepackage{color}
- \usepackage{hyperref}
- \usepackage{multimedia}
- \PassOptionsToPackage{pdfmark}{hyperref}\RequirePackage{hyperref}
- \pgfdeclareimage[height=0.12\textheight]{university-logo}{../../UWlogo.png}
- \logo{\pgfuseimage{university-logo}}
- \newcommand{\ve}[1]{\mathbf{#1}}
- \newcommand{\pop}[1]{\mathcal{#1}}
- \newcommand{\samp}[1]{\mathcal{#1}}
- \newcommand{\subspace}[1]{\mathcal{#1}}
- \newcommand{\sv}[1]{\boldsymbol{#1}}
- \newcommand{\sm}[1]{\boldsymbol{#1}}
- \newcommand{\tr}[1]{{#1}^{\mkern-1.5mu\mathsf{T}}}
- \newcommand{\abs}[1]{\left\lvert ~{#1} ~\right\rvert}
- \newcommand{\size}[1]{\left\lvert {#1} \right\rvert}
- \newcommand{\norm}[1]{\left|\left|{#1}\right|\right|}
- \newcommand{\field}[1]{\mathbb{#1}}
- \newcommand{\Reals}{\field{R}}
- \newcommand{\Integers}{\field{Z}}
- \newcommand{\Naturals}{\field{N}}
- \newcommand{\Complex}{\field{C}}
- \newcommand{\Rationals}{\field{Q}}
- \newcommand{\widebar}[1]{\overline{#1}}
- \newcommand{\wig}[1]{\tilde{#1}}
- \newcommand{\bigwig}[1]{\widetilde{#1}}
- \newcommand{\leftgiven}{~\left\lvert~}
- \newcommand{\given}{~\vert~}
- \newcommand{\indep}{\bot\hspace{-.6em}\bot}
- \newcommand{\notindep}{\bot\hspace{-.6em}\bot\hspace{-0.75em}/\hspace{.4em}}
- \newcommand{\depend}{\Join}
- \newcommand{\notdepend}{\Join\hspace{-0.9 em}/\hspace{.4em}}
- \newcommand{\imply}{\Longrightarrow}
- \newcommand{\notimply}{\Longrightarrow \hspace{-1.5em}/ \hspace{0.8em}}
- \newcommand*{\intersect}{\cap}
- \newcommand*{\union}{\cup}
- \DeclareMathOperator*{\argmin}{arg\,min}
- \DeclareMathOperator*{\argmax}{arg\,max}
- \DeclareMathOperator*{\Ave}{Ave\,}
- \newcommand{\suchthat}{~:~}
- \newcommand{\st}{~:~} 
- \newcommand{\code}[1]{\texttt{#1}}
- \newcommand*{\Rnsp}{\textsf{R}}
- \newcommand*{\R}{\textsf{R}$~$}
- \newcommand*{\loonnsp}{\textsf{loon}}
- \newcommand*{\loon}{\textsf{loon}$~$}
- \newcommand*{\Pythonnsp}{\textsf{Python}}
- \newcommand*{\Python}{\textsf{Python}$~$}
- \newcommand*{\Tclnsp}{\textsf{Tcl}}
- \newcommand*{\Tcl}{\textsf{Tcl}$~$}
- \newcommand{\pkg}[1]{\textsf{#1}}
- \newcommand{\pkgsp}[1]{\textsf{#1}$~$}
- \newcommand{\lpart}[1]{\textsf{#1}}
- \newcommand{\lpartsp}[1]{\textsf{#1}$~$}
- \newcommand{\togglepause}{\pause}
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center", 
                      fig.width = 7, 
                      fig.height = 6,
                      out.height = "60%")
set.seed(12314159)
library(loon.data)
library(loon)
library(gridExtra)

imageDirectory <- "./img"
dataDirectory <- "./data"
path_concat <- function(path1, path2, sep="/") paste(path1, path2, sep = sep)
```


---

## Example: Cosmetic company on Facebook

By 2014, Facebook was the most used social network averaging about 1.28 billion monthly active users. \togglepause

A cosmetics company had been using a Facebook page they created to reach their customers as well as potential customers.  \togglepause

Likely, the page had been active for a few years, when they decided to investigate the effectiveness of the various postings they had made on their page.  \togglepause

To get some idea, they decided to collect all of the posts they published in 2014 (January 1 to December 31) together with different features recorded on each post. \togglepause

**Questions:**

\begin{itemize}
\item What is a unit here? \togglepause
\item What is the target population? \togglepause
\item The study population? \togglepause
\item The sample?
\end{itemize}

\scriptsize
Source: 

S. Moro, P. Rita and B. Vala (2016). ``Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach''. *Journal of Business Research*, *69*, pp. 3341-3351.

---

## The inductive path components

A post on the company's Facebook page is a **unit**

The **target population** is the set of all such posts (*including all posts in the near/foreseeable future*)

The **study population** is the set of all of the posts that the company had made *to date*.

The **sample** is the set of posts in the year. \togglepause
There were a total of 790 such posts. \togglepause
Unfortunately, of these only 500 are available to us. \togglepause
So **our sample** is only of size 500, taken from the 790 in 2014.  We don't know how these were chosen. \togglepause

The company recorded 19 **variates** on each post. \togglepause
Only 13 of these are recorded in our dataset. 
 \togglepause

Don't really have any population attributes (yet).


---

## The variates

For each post, values of the following 13 variates were recorded: \togglepause
\footnotesize

- `share`: the total (lifetime) number of times the post was shared \togglepause

- `like`: the total (lifetime)  number of times the post "liked" \togglepause

- `comment`: the total (lifetime)  number of comments attached to the post \togglepause
- `All.interactions`: the sum of `share`, `like`, and `comment` \togglepause
- `Page.likes`:  the number of "likes" for the facebook page at the original time of the posting \togglepause
- `Impressions`: the total (lifetime)  number of times the post has been displayed, whether the post is clicked or not. The same post may be seen by a facebook user several times (e.g. via a page update in their News Feed once, whenever a friend shares it, etc.). \togglepause
- `Impressions.when.page.liked`: the total (lifetime)  number of times the post has been displayed to someone who has "liked" the page \togglepause
- `Post.Hour`: the hour of the day at the original time of the posting (0-23) \togglepause
- `Post.Weekday`: the day of the week at the original time of the posting (1-7) beginning with Sunday  \togglepause
- `Post.Month`: the month of the year at the original time of the posting (1-12)     \togglepause
- `Category`: the category of the post (as determined by two separate human reviewers according to the campaign associated with the post), one of `Action` (special offers and contests), `Product` (direct advertisement, explicit brand content), or `Inspiration` (non-explicit brand related content)  \togglepause
- `Type`: the type of content of the post, one of `Link`, `Photo`, `Status`, or `Video` \togglepause
- `Paid`: 1 if the company paid Facebook for advertising, 0 otherwise


---

## The variates - explanatory or response?

It can be useful to separate variates into two different groups according to whether we are (perhaps only temporarily) thinking of them as **response** variates or as **explanatory** variates. \togglepause

Here the company is curious about the effect of each posting so any variate that relates to the characteristics of the posting itself could be explanatory, whereas those that might measure the reaction of a viewer to the posting would be possible response variates. \togglepause

Note that oftentimes, but not always, explanatory variates are in our control (i.e. we can either *select units* that have specific values or *assign values* to units) and response variates are not. \togglepause

\footnotesize
For example, **explanatory variates** could include those related to the time of the post (`Post.hour`, `Post.day`,`Post.month`), the `Type` of the post (one of `Link`, `Photo`, `Status`, or `Video`), the `Category` of post (one of `Action`, `Product`, or `Inspiration`), and whether the post was `Paid` advertising.  Any of these could have their value assigned to the post.  An explanatory variate whose value could have been somewhat selected would be the number of "likes" the Facebook page had accrued at the time of the post.  \togglepause

**Response variates** would then include the number of times the post was shared, liked, commented on, the number of times the post was displayed (`Impressions`), and the number of times to someone who indicated they had liked the page (`Impressions.when.page.liked`). \togglepause

Sometimes, as with  `Page.likes`, `Impressions`, `Impressions.when.page.liked`, variates might be considered as response variates for one purpose and as explantory ones for another.

---

## The data

The first and last few rows of the data:

\footnotesize
```{r read in facebook}
file <- path_concat(dataDirectory, "facebook.csv")
facebook <- read.csv(file)
head(facebook, n = 4)
tail(facebook, n = 4)
```


---

## The data - summary

\scriptsize
```{r summary facebook}
summary(facebook)
```
---

## The data - plot summary

\scriptsize
```{r plot facebook, out.height= "80%"}
plot(facebook, gap = 0, pch =".")
```


---

## The data - interactive plot summaries

\scriptsize
```{r l_barPlots1, eval = FALSE}
library(loon)
findCatVars <- function(data) {
    isCatVar <- sapply(names(data), 
                       FUN  = function(name) {is.factor(data[,name])})
    catVars <- names(data)[isCatVar]
    catVars
}

l_barPlots <- function(data, linkingGroup,  together = TRUE){
    if(missing(linkingGroup)) {
        linkingGroup <- deparse(substitute(data)) # use the data frame name
        }
    catVars <- findCatVars(data)
    if (together){
        parent <- tktoplevel()
        tktitle(parent) <- "Counts for factors"
        nrows <- floor(sqrt(length(catVars)))
        ncols <- ceiling(sqrt(length(catVars)))
        row <- 0
        col <- 0
        for (var in catVars) {
            barplot <- l_hist(data[,var], 
                              linkingGroup = linkingGroup,
                              title = var,
                              xlabel = var,
                              parent = parent)
            if (col >= ncols){ 
                row <- row + 1
                col <- 0}
            tkgrid(barplot, row = row, column = col, sticky = "nesw")
            col <- col + 1}
        # Continued next slide
        # ...
```


---

## The data - interactive plot summaries

\scriptsize
```{r l_barPlots2, eval = FALSE}
        # ...
        # Continued from previous slide
        # Configure columns to resize with window
        for (col in 0:(ncols-1)){
            tkgrid.columnconfigure(parent, col, weight = 1)}
        # Configure rows to resize with window
        for (row in 0:(nrows-1)){
            tkgrid.rowconfigure(parent, row, weight = 1)}
    } else {
        for (var in catVars) {
            barplot <- l_hist(data[,var], 
                              linkingGroup = linkingGroup,
                              title = var,
                              xlabel = var)
            
        }
    }
}
```

\normalsize
Can now call `l_barPlots()` on our data set:
```{r l_barPlots, echo = FALSE}
library(loon)
findCatVars <- function(data) {
    isCatVar <- sapply(names(data), 
                       FUN  = function(name) {
                           is.factor(data[,name])
                           })
    catVars <- names(data)[isCatVar]
    catVars
}

l_barPlots <- function(data, linkingGroup,  together = TRUE){
    if(missing(linkingGroup)) {
        linkingGroup <- deparse(substitute(data)) # use the data frame name
        }
    catVars <- findCatVars(data)
    if (together){
        parent <- tktoplevel()
        tktitle(parent) <- "Counts for factors"
        nrows <- floor(sqrt(length(catVars)))
        ncols <- ceiling(sqrt(length(catVars)))
        row <- 0
        col <- 0
        for (var in catVars) {
            barplot <- l_hist(data[,var], 
                              linkingGroup = linkingGroup,
                              title = var,
                              xlabel = var,
                              parent = parent)
            if (col >= ncols){ 
                row <- row + 1
                col <- 0}
            tkgrid(barplot, row = row, column = col, sticky = "nesw")
            col <- col + 1}
        
        # Configure columns to resize with window
        for (col in 0:(ncols-1)){
            tkgrid.columnconfigure(parent, col, weight = 1)}
        # Configure rows to resize with window
        for (row in 0:(nrows-1)){
            tkgrid.rowconfigure(parent, row, weight = 1)}
    } else {
        for (var in catVars) {
            barplot <- l_hist(data[,var], 
                              linkingGroup = linkingGroup,
                              title = var,
                              xlabel = var)
            
        }
    }
}
```

\footnotesize
```{r call l_barPlots}
bp <- l_barPlots(facebook)
```

\normalsize
And a pairs plot

\footnotesize
```{r call l_pairs}
vars <- setdiff(names(facebook), findCatVars(facebook))
pp <- l_pairs(facebook[, vars], glyph = "ocircle", size = 2,
              showHistograms = TRUE,
              linkingGroup = "facebook")
```

---

## Relationships between pairs of variates

From the plots there are some obvious fairly strong relationships. \togglepause
Notably,

```{r strong relations, echo = FALSE, fig.width = 12, out.height = "40%"}
pLikesAll <- with(facebook, 
           l_plot(like, All.interactions, linkingGroup = "facebook")
)
pMonthPageLikes <- with(facebook, 
           l_plot(Post.Month, Page.likes, linkingGroup = "facebook")
)

grid.arrange(plot(pLikesAll, draw = FALSE), 
             plot(pMonthPageLikes, draw = FALSE),
             nrow = 1)
```

\togglepause
But then, `All.interactions` = sum of `share`, `like`, and `comment` which appears to be dominated by `like`. \togglepause

Also, `Page.likes` are total Facebook page likes at the time of posting.  The number of `Page.likes` is necessarily non-decreasing in time. \togglepause

In both cases, it would seem that there is a very strong relation between the variates in each pair.  One or the other of each pair might be discarded.

---

## Relationships between pairs of variates

For many other plots there also appears to be a relationship, though fairly weak. \togglepause
For example,

```{r weak relations, echo = FALSE, fig.width = 12, out.height = "40%"}
pLikeComment <- with(facebook, 
                     l_plot(like, comment, linkingGroup = "facebook")
)
pAllInteractionsImpressions <- with(facebook, 
           l_plot(All.interactions, Impressions, linkingGroup = "facebook")
)

grid.arrange(plot(pLikeComment, draw = FALSE), 
             plot(pAllInteractionsImpressions, draw = FALSE),
             nrow = 1)
```

\togglepause

---

## Transforming variates

All of the response variates appear to have severely skewed distributions (e.g. `share`, `like`, etc.).  We might consider a monotonic (and order preserving) transformation such as the logarithm. \togglepause

Note that zero occurs in the counts for `All.interactions`, `share`, `like`, and `comment`, so we add a small amount first (+1) to all of these. 

\footnotesize
```{r new variables}
facebooklog10 <- data.frame(
       log10(1 + 
             facebook[, c("All.interactions", "share", "like", "comment")]),
       log10(facebook[, c("Impressions.when.page.liked", "Impressions")])
)
names(facebooklog10) <- paste("log10", names(facebooklog10), sep = ".")
head(facebooklog10)
```

---

## Transforming variates

\footnotesize
```{r pairs plot of new variables}
pplog10 <- l_pairs(facebooklog10, glyph = "ocircle", 
                   linkingGroup = "facebook", showHistograms = TRUE)
plot(pplog10)
```

Some histograms look more symmetric, less skewed.  Others look skewed in the opposite direction. \togglepause

Similarly, some plots look more like straight lines; others look like they are now spread out a lot on the left instead of the right.



---

## Transforming variates

For example, compare these plots:
\footnotesize
```{r comparing new variables, echo = FALSE}
plog10LikeComment <- with(facebooklog10, 
                     l_plot(log10.like, log10.comment, linkingGroup = "facebook")
)
plog10AllInteractionsImpressions <- with(facebooklog10, 
           l_plot(log10.All.interactions, log10.Impressions, linkingGroup = "facebook")
)

grid.arrange(plot(pLikeComment, draw = FALSE), 
             plot(plog10LikeComment, draw = FALSE), 
             plot(pAllInteractionsImpressions, draw = FALSE),
             plot(plog10AllInteractionsImpressions, draw = FALSE),
             nrow = 2)
```

Is there some way of not going too far?

---

## The family of power transformations

When $x>0$, one possible "family" of transformations is the power family.

For $x > 0$, we can write this family (over the power $\alpha$) as
\[T_\alpha(x) = \left\{
\begin{array}{cc}
 ax^\alpha + b & ( \alpha \ne 0 )   \\
c \log(x) +d &      (\alpha=0) 
\end{array}
\right.
\]
where $a,b,c,d$ and $\alpha$ are real numbers with
$a > 0$ when $\alpha>0$, $a<0$ when $\alpha <0$, and $c>0$ when $\alpha=0$.
The choices of $a, b, c$ and $d$ are somewhat arbitrary otherwise.

Since location and scale are not important in determining the **shape** of the distribution, we might settle on particular choices which are more mathematicallly convenient. For example,
\[T_\alpha(x) = 
\frac{x^\alpha -1}{\alpha} ~~~~ \forall ~ \alpha 
\]
which requires no separate equation for the $x=0$ case, since $lim_{\alpha \rightarrow 0} T_{\alpha}(x) = log(x)$.


---

## The family of power transformations
\small
We could have different values of $\alpha$, say $\alpha_x$ and $\alpha_y$, respectively for $x$ and $y$ points in a scatterplot. \togglepause
In \loon, we can create an interactive tool that allows us to view a scatterplot of pairs $(T_{\alpha_x}(x), T_{\alpha_y}(y))$ as we vary $\alpha_x$ and $\alpha_y$.  \togglepause

The code looks like this:
\footnotesize
```{r, eval=FALSE}
power_xy <- function(x, y=NULL, xlab=NULL, ylab=NULL,  
                     linkingGroup, 
                     linkingKey, from = -5, to = 5, 
                     ...) {
    if (is.null(xlab)) {xlab <- "x"}
    if (is.null(ylab)) {ylab <- "y"} 
    if (missing(linkingKey)) {linkingKey <- paste0(seq(0, length(x) -1))}
    if (missing(linkingGroup)) {linkingGroup <- deparse(substitute(x))}
    
    powerfun <- function(x, alpha) {
        if (alpha == 0) log(x) else (x^alpha-1)/alpha}
    
    scale01 <- function(x) {
        minx <- min(x, na.rm = TRUE)
        maxx <- max(x, na.rm = TRUE)
        (x-minx)/(maxx - minx) + 1}
    
    tt <- tktoplevel()
    xs <- scale01(x)
    ys <- scale01(y)
    # CONTINUED ON NEXT SLIDE
```

---

## The family of power transformations

\footnotesize
```{r, eval=FALSE}
    # CONTINUED FROM PREVIOUS
    # scatterplot
    p <- l_plot(x=xs, y=ys, xlabel=xlab, ylabel=ylab, 
                linkingGroup = linkingGroup, 
                linkingKey = linkingKey,
                parent=tt, ...)
    # Save the x and y values from p
    xy_p <- data.frame(x = p["x"], y = p["y"])
    
    fit <- lm(y ~ x, data = xy_p)
    # layer fit
    xrng <- range(xy_p$x)
    yhat <- predict(fit, data.frame(x = xrng))
    line <- l_layer_line(p, x = xrng, y = yhat, linewidth = 3, index = "end")
    # histogram on each
    h_x <- l_hist(xs, xlabel=xlab, yshows="density", 
                  linkingGroup = linkingGroup, linkingKey = linkingKey)
    h_y <- l_hist(ys, xlabel=ylab, yshows="density",  
                  linkingGroup = linkingGroup, linkingKey = linkingKey,
                  swapAxes = TRUE)
    # save the original histogram values
    h_x_vals <- h_x["x"]
    h_y_vals <- h_y["x"]
    # CONTINUED ON NEXT SLIDE
```

---

## The family of power transformations

\footnotesize
```{r, eval=FALSE}
    # CONTINUED FROM PREVIOUS SLIDE 
    
    # Set up power transformations
    alpha_x <- tclVar('1')
    alpha_y <- tclVar('1')
    
    # Create two slider scales for the two powers
    # Reverse to and from because scales are vertical
    sx <- tkscale(tt, orient='vertical', label='power x', variable=alpha_x,
                  from=to, to=from, resolution=0.1)
    sy <- tkscale(tt, orient='vertical', label='power y', variable=alpha_y,
                  from=to, to=from, resolution=0.1)
    
    # pack the sliders into the same window as the scatterplot
    tkpack(sy, sx, fill='y', side='right')
    tkpack(p, fill='both', expand=TRUE)
    
    # CONTINUED on NEXT SLIDE
```

---

## The family of power transformations

\footnotesize
```{r, eval=FALSE}
    # CONTINUED FROM PREVIOUS SLIDE 
    # the update function, called when sliders move
    update <- function(...) {
        ## powers
        alphax <- as.numeric(tclvalue(alpha_x))
        alphay <- as.numeric(tclvalue(alpha_y))
        
        ## labels
        xlabel <- if (alphax==0) {
            paste0("log(",xlab,")")
        } else {
            if (alphax==1) {
                xlab
            } else {
                paste0(xlab,"^",alphax)
            }
        }
        ylabel <- if (alphay==0) {
            paste0("log(",ylab,")")
        } else {
            if (alphay==1) {
                ylab
            } else {
                paste0(ylab,"^",alphay)
            }
        }
    
        # CONTINUED on NEXT SLIDE
```

---

## The family of power transformations

\footnotesize
```{r, eval=FALSE}
        # CONTINUED FROM PREVIOUS SLIDE
        # 
        # new plot x and y
        p_xnew <- scale01(powerfun(xy_p$x, alphax))
        p_xnew_range <- range(p_xnew)
        p_ynew <- scale01(powerfun(xy_p$y, alphay))
        
        # update the fitted line values
        fit.temp <- lm(p_ynew ~ p_xnew)
        yhat <- predict(fit.temp, data.frame(p_xnew = p_xnew_range))
        l_configure(line, y = yhat, x = p_xnew_range)
        
        # update plot
        l_configure(p,
                    x = p_xnew,
                    y = p_ynew,
                    xlabel = xlabel,
                    ylabel = ylabel
        )
        l_scaleto_world(p)
    
        # CONTINUED on NEXT SLIDE
```

---

## The family of power transformations

\footnotesize
```{r, eval=FALSE}
        # CONTINUED FROM PREVIOUS SLIDE
        # update the histograms
        binwidthx <- h_x['binwidth']
        binwidthy <- h_y['binwidth']
        h_x_vals_new <- scale01(powerfun(h_x_vals, alphax))
        h_y_vals_new <- scale01(powerfun(h_y_vals, alphay))
        l_configure(h_x, x = h_x_vals_new,
                    binwidth = binwidthx,
                    #origin = originx,
                    yshows="density",
                    xlabel= xlabel)
        l_configure(h_y, x = h_y_vals_new,
                    binwidth = binwidthy,
                    #origin = originy,
                    yshows="density",
                    xlabel= ylabel)
        l_scaleto_plot(h_x)
        l_scaleto_plot(h_y)
    } 
    # end of update function
    # attach the update to the sliders
    tkconfigure(sx, command=update)
    tkconfigure(sy, command=update)
    invisible(p)
}
```

---

## The family of power transformations

We can now try this function out in \loon.

```{r power_xy, eval=TRUE, echo=FALSE}
power_xy <- function(x, y=NULL, xlab=NULL, ylab=NULL,  
                     linkingGroup, 
                     linkingKey, from = -5, to = 5, 
                     ...) {
    if (is.null(xlab)) {xlab <- "x"}
    if (is.null(ylab)) {ylab <- "y"} 
    if (missing(linkingKey)) {
        linkingKey <- paste0(seq(0, length(x) -1))
    }
    if (missing(linkingGroup)) {
        linkingGroup <- deparse(substitute(x))
    }
    
    powerfun <- function(x, alpha) {
        if (alpha == 0) log(x) else (x^alpha-1)/alpha}
    
    scale01 <- function(x) {
        minx <- min(x, na.rm = TRUE)
        maxx <- max(x, na.rm = TRUE)
        (x-minx)/(maxx - minx) + 1
    }
    
    tt <- tktoplevel()
    xs <- scale01(x)
    ys <- scale01(y)
    
    # scatterplot
    p <- l_plot(x=xs, y=ys, xlabel=xlab, ylabel=ylab, 
                linkingGroup = linkingGroup, 
                linkingKey = linkingKey,
                parent=tt, ...)
    # Save the x and y values from p
    xy_p <- data.frame(x = p["x"], y = p["y"])
    
    fit <- lm(y ~ x, data = xy_p)
    # layer fit
    xrng <- range(xy_p$x)
    yhat <- predict(fit, data.frame(x = xrng))
    line <- l_layer_line(p, x = xrng, y = yhat, 
                         linewidth = 3, index = "end")
    
    # histogram on each
    h_x <- l_hist(xs, xlabel=xlab, yshows="density", 
                  linkingGroup = linkingGroup, linkingKey = linkingKey)
    h_y <- l_hist(ys, xlabel=ylab, yshows="density",  
                  linkingGroup = linkingGroup, linkingKey = linkingKey,
                  swapAxes = TRUE)
    # save the original histogram values
    h_x_vals <- h_x["x"]
    h_y_vals <- h_y["x"]
    
    # Set up power transformations
    alpha_x <- tclVar('1')
    alpha_y <- tclVar('1')
    
    # Create two slider scales for the two powers
    # Reverse to and from because scales are vertical
    sx <- tkscale(tt, orient='vertical', label='power x', variable=alpha_x,
                  from=to, to=from, resolution=0.1)
    sy <- tkscale(tt, orient='vertical', label='power y', variable=alpha_y,
                  from=to, to=from, resolution=0.1)
    
    # pack the sliders into the same window as the scatterplot
    tkpack(sy, sx, fill='y', side='right')
    tkpack(p, fill='both', expand=TRUE)
    
    
    # the update function, called when sliders move
    update <- function(...) {
        ## powers
        alphax <- as.numeric(tclvalue(alpha_x))
        alphay <- as.numeric(tclvalue(alpha_y))
        
        ## labels
        xlabel <- if (alphax==0) {
            paste0("log(",xlab,")")
        } else {
            if (alphax==1) {
                xlab
            } else {
                paste0(xlab,"^",alphax)
            }
        }
        ylabel <- if (alphay==0) {
            paste0("log(",ylab,")")
        } else {
            if (alphay==1) {
                ylab
            } else {
                paste0(ylab,"^",alphay)
            }
        }
        # new plot x and y
        p_xnew <- scale01(powerfun(xy_p$x, alphax))
        p_xnew_range <- range(p_xnew)
        p_ynew <- scale01(powerfun(xy_p$y, alphay))
        
        # update the fitted line values
        fit.temp <- lm(p_ynew ~ p_xnew)
        yhat <- predict(fit.temp, data.frame(p_xnew = p_xnew_range))
        l_configure(line, y = yhat, x = p_xnew_range)
        
        # update plot
        l_configure(p,
                    x = p_xnew,
                    y = p_ynew,
                    xlabel = xlabel,
                    ylabel = ylabel
        )
        l_scaleto_world(p)
        
        # update the histograms
        binwidthx <- h_x['binwidth']
        binwidthy <- h_y['binwidth']
        h_x_vals_new <- scale01(powerfun(h_x_vals, alphax))
        h_y_vals_new <- scale01(powerfun(h_y_vals, alphay))
        l_configure(h_x, x = h_x_vals_new,
                    binwidth = binwidthx,
                    #origin = originx,
                    yshows="density",
                    xlabel= xlabel)
        l_configure(h_y, x = h_y_vals_new,
                    binwidth = binwidthy,
                    #origin = originy,
                    yshows="density",
                    xlabel= ylabel)
        l_scaleto_plot(h_x)
        l_scaleto_plot(h_y)
    }
    # end of update function
    # 
    # attach the update to the sliders
    tkconfigure(sx, command=update)
    tkconfigure(sy, command=update)
    invisible(p)
}
```

\footnotesize
```{r prepare power_xy}
# Need to get a version of facebook and if necessary remove nas with na.omit()
# 
# First add 1 where necessary
# 
facebook1 <- facebook
facebook1[,c("All.interactions", "share", 
             "like", "comment")] <- 1 + facebook[, c("All.interactions", "share", 
                                                     "like", "comment")]

# 
# facebook1 <- na.omit(facebook1) # USE THIS
# 

p_MonthPageLikes <- with(facebook1,
                         power_xy(x=Post.Month, y=Page.likes, 
                                  xlab="month of post", ylab="number page likes",
                                  title = "Page likes vs month",
                                  linkingGroup = "facebook",
                                  itemLabel = paste0("Category: ", Category, "\n",
                                                     "Type: ", Type, "\n",
                                                     "Paid: ", 
                                                     c("no", "yes")[Paid]),
                                  showItemLabels = TRUE))
```


---

## The family of power transformations

Try this function out on the "like" and "share" variates.  We need a wider range of powers.

\footnotesize
```{r power_xy like and share}
p_likeShare <- with(facebook1,
                    power_xy(x=like, y=share, xlab="likes", ylab="shares",
                             from = -30, to = 10,
                             title = "shares vs likes",
                             linkingGroup = "facebook",
                             itemLabel = paste0("Category: ", Category, "\n",
                                                "Type: ", Type, "\n",
                                                "Paid: ", c("no", "yes")[Paid]),
                             showItemLabels = TRUE))
```

---

## Tukey's ladder of power transformations

\scriptsize
```{r}
#  A convenient mnemonic  ....
#
#  Tukey's "ladder" of power transformations
# ... -2, -1, -1/2, -1/3, 0, 1/3, 1/2, 1, 2, ...
#   <--- down            up -->        ^start
#
#     Or, as a ladder:
#                    
#                   Power
#                 _________
#                     .
#                     .
#                     .
#                 _________
#                     2
#                 _________
#                     1      <-- raw data (start)
#                 _________
#                    1/2
#                 _________
#                     0      <-- logarithm
#                 _________
#                   -1/2
#                 _________
#                    -1
#                 _________
#                    -2
#                 _________
#
#                    Etc.   
```

\footnotesize
John Tukey suggested imagining that the powers were arranged in a "ladder"  with the smallest powers on the bottom and the largest on the top.


---

## Tukey's ladder of power transformations - Bump rules

\normalsize

**Bump rule 1** for making densities (histograms) more symmetric.

The location of the density's bump (mode) tells you which way to "move" on the ladder. \togglepause

- if it is concentrated on "lower" values, \togglepause
  then move the power "lower" on the ladder
    - i.e. move down the ladder
- if it is concentrated on "higher" values, \togglepause
  then move the power "higher" on the ladder
    - i.e. move up the ladder \togglepause

**Bump rule 2** for straightening scatterplots.

Bump is now the direction of the curve of the scatterplot, \togglepause

Bump points to a direction on the $x$ axis AND on a (possibly different) direction on the $y$ axis. \togglepause

- Bump pointing up (or down) on the $x$ axis means move up (or down) on $\alpha_x$ ladder. \togglepause
- Bump pointing up (or down) on the $y$ axis means move up (or down) on $\alpha_y$ ladder. \togglepause

---

## Tukey's ladder of power transformations - Bump rules

![Rule of the bump](./img/bumpRule.png)

---

## Fitting models to data

Consider, for example, the plots and fitted lines produced by the code below.

\footnotesize
```{r fits, echo=TRUE, eval = FALSE, fig.width=8, fig.height= 8}
fit1 <- lm(log(like + 1) ~ log(Impressions), data = facebook)
fit2 <- lm(log(All.interactions +1) ~ Post.Month, data = facebook)
fit3 <- lm(log(Impressions) ~ Paid, data = facebook)
fit4 <- lm(log(Impressions.when.page.liked) ~ log(Page.likes + 1), data = facebook)

savePar <- par(mfrow=c(2,2))
colour <- adjustcolor("firebrick", 0.5)
with(facebook,
     { plot(log(Impressions), log(like + 1), ylab = "log(like)", pch=19, col=colour)
       abline(fit1, col="steelblue", lwd=2)
       plot(Post.Month, log(All.interactions +1), ylab = "log(all)", pch=19, col=colour)
       abline(fit2, col="steelblue", lwd=2)
       plot(Paid, log(Impressions), pch=19, col=colour)
       abline(fit3, col="steelblue", lwd=2)
       plot(log(Page.likes + 1), log(Impressions.when.page.liked), 
            ylab = "log(impressions when liked)", xlab = "log(page likes)",
            pch=19, col=colour)
       abline(fit4, col="steelblue", lwd=2)
       }
    )
par(savePar)
```

---

## Fitting models to data

Results are:

```{r fits plots, eval=TRUE, echo = FALSE, fig.width=16, fig.height= 16}
fit1 <- lm(log(like + 1) ~ log(Impressions), data = facebook)
fit2 <- lm(log(All.interactions +1) ~ Post.Month, data = facebook)
fit3 <- lm(log(Impressions) ~ Paid, data = facebook)
fit4 <- lm(log(Impressions.when.page.liked) ~ log(Page.likes + 1), data = facebook)

savePar <- par(mfrow=c(2,2))
colour <- adjustcolor("firebrick", 0.5)
with(facebook,
     { plot(log(Impressions), log(like + 1), ylab = "log(like)", pch=19, col=colour)
       abline(fit1, col="steelblue", lwd=2)
       plot(Post.Month, log(All.interactions +1), ylab = "log(all)", pch=19, col=colour)
       abline(fit2, col="steelblue", lwd=2)
       plot(Paid, log(Impressions), pch=19, col=colour)
       abline(fit3, col="steelblue", lwd=2)
       plot(log(Page.likes + 1), log(Impressions.when.page.liked), 
            ylab = "log(impressions when liked)", xlab = "log(page likes)",
            pch=19, col=colour)
       abline(fit4, col="steelblue", lwd=2)
       }
    )
par(savePar)
```


---

## Fitting models to data

First fit results:
\footnotesize
```{r}
summary(fit1)
```

---

## Fitting models to data

First fit results:
\footnotesize
```{r}
oldPar <- par(mfrow=c(2,2))
plot(fit1)
par(oldPar)
```

---

## Fitting models to data

Second fit results:
\footnotesize
```{r}
summary(fit2)
```


---

## Fitting models to data

Second fit results:
\footnotesize
```{r}
oldPar <- par(mfrow=c(2,2))
plot(fit2)
par(oldPar)
```

---

## Fitting models to data

Third fit results:
\footnotesize
```{r}
summary(fit3)
```


---

## Fitting models to data

Third fit results:
\footnotesize
```{r}
oldPar <- par(mfrow=c(2,2))
plot(fit3)
par(oldPar)
```

---

## Fitting models to data

Fourth fit results:
\footnotesize
```{r}
summary(fit4)
```

---

## Fitting models to data

Fourth fit results:
\footnotesize
```{r}
oldPar <- par(mfrow=c(2,2))
plot(fit4)
par(oldPar)
```

---

## Fitting models to data

How about:
\footnotesize
```{r}
fit5 <- lm(I(Page.likes^3) ~ sqrt(Post.Month), data = facebook)
```
\togglepause
```{r}
summary(fit5)
```


---

## Fitting models to data

Fifth fit results:
\footnotesize
```{r}
plot(fit5$fitted.values, fit5$residuals, 
     xlab = "fitted values", ylab = "residuals",
     main = "Transformed Page.likes and Post.Month",
     sub = "residual plot", xaxt ="n"
)
axis(side=1,  labels = month.abb,
     at = predict(fit5,
                  newdata = 
                      data.frame(Post.Month = sort(unique(facebook$Post.Month)))))
```
