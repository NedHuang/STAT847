---
title: "Random sampling plans"
output:
  pdf_document:
    keep_tex: no
    latex_engine: xelatex
    number_sections: yes
  html_document:
    toc: yes
  word_document: default
fontsize: 9pt
urlcolor: blue
header-includes:
- \usepackage{graphicx}
- \usepackage{epic}
- \usepackage{color}
- \usepackage{hyperref}
- \usepackage{multimedia}
- \newcommand{\ve}[1]{\mathbf{#1}}
- \newcommand{\pop}[1]{\mathcal{#1}}
- \newcommand{\samp}[1]{\mathcal{#1}}
- \newcommand{\subspace}[1]{\mathcal{#1}}
- \newcommand{\sv}[1]{\boldsymbol{#1}}
- \newcommand{\sm}[1]{\boldsymbol{#1}}
- \newcommand{\tr}[1]{{#1}^{\mkern-1.5mu\mathsf{T}}}
- \newcommand{\abs}[1]{\left\lvert ~{#1} ~\right\rvert}
- \newcommand{\size}[1]{\left\lvert {#1} \right\rvert}
- \newcommand{\norm}[1]{\left|\left|{#1}\right|\right|}
- \newcommand{\field}[1]{\mathbb{#1}}
- \newcommand{\Reals}{\field{R}}
- \newcommand{\Integers}{\field{Z}}
- \newcommand{\Naturals}{\field{N}}
- \newcommand{\Complex}{\field{C}}
- \newcommand{\Rationals}{\field{Q}}
- \newcommand{\widebar}[1]{\overline{#1}}
- \newcommand{\wig}[1]{\tilde{#1}}
- \newcommand{\bigwig}[1]{\widetilde{#1}}
- \newcommand{\leftgiven}{~\left\lvert~}
- \newcommand{\given}{~\vert~}
- \newcommand{\indep}{\bot\hspace{-.6em}\bot}
- \newcommand{\notindep}{\bot\hspace{-.6em}\bot\hspace{-0.75em}/\hspace{.4em}}
- \newcommand{\depend}{\Join}
- \newcommand{\notdepend}{\Join\hspace{-0.9 em}/\hspace{.4em}}
- \newcommand{\imply}{\Longrightarrow}
- \newcommand{\notimply}{\Longrightarrow \hspace{-1.5em}/ \hspace{0.8em}}
- \newcommand*{\intersect}{\cap}
- \newcommand*{\union}{\cup}
- \DeclareMathOperator*{\argmin}{arg\,min}
- \DeclareMathOperator*{\argmax}{arg\,max}
- \DeclareMathOperator*{\Ave}{Ave\,}
- \newcommand{\suchthat}{~:~}
- \newcommand{\st}{~:~} 
- \newcommand{\code}[1]{\texttt{#1}}
- \newcommand*{\Rnsp}{\textsf{R}}
- \newcommand*{\R}{\textsf{R}$~$}
- \newcommand*{\loonnsp}{\textsf{loon}}
- \newcommand*{\loon}{\textsf{loon}$~$}
- \newcommand*{\Pythonnsp}{\textsf{Python}}
- \newcommand*{\Python}{\textsf{Python}$~$}
- \newcommand*{\Tclnsp}{\textsf{Tcl}}
- \newcommand*{\Tcl}{\textsf{Tcl}$~$}
- \newcommand{\pkg}[1]{\textsf{#1}}
- \newcommand{\pkgsp}[1]{\textsf{#1}$~$}
- \newcommand{\lpart}[1]{\textsf{#1}}
- \newcommand{\lpartsp}[1]{\textsf{#1}$~$}
- \newcommand{\togglepause}{\pause}
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center", 
                      fig.width = 7, 
                      fig.height = 6,
                      out.height = "60%")
set.seed(12314159)
library(loon.data)
library(loon)
library(gridExtra)

codeDirectory <- "../../img"
imageDirectory <- "./img"
dataDirectory <- "./data"
path_concat <- function(path1, path2, sep="/") paste(path1, path2, sep = sep)
```

```{r pathSetup, eval = FALSE}
## Set this up for your own directory
imageDirectory <- "MyAssignmentDirectory/img"  # e.g. in current "./img"
dataDirectory <- "MyAssignmentDirectory/data"  # e.g. in current "./data"
path_concat <- function(path1, path2, sep="/") paste(path1, path2, sep = sep)
```

---

**47 marks**

Consider the study population $\pop{P}_{Study}$ of $N = 100$ blocks of uniform thickness and density (all blocks were cut from the same opaque plastic sheet of about 5 mm thickness), but have different shapes such as those shown below:
\begin{center}
\includegraphics[width= 0.7\textwidth]{./img/blocks.png}
\end{center}

Data on this population of 100 blocks are available as an \R data set `blocks`.  This data set has four variates: block `id` number, `weight` in grams, `perimeter` in centimetres, and the `group` of the block (being either `A` or `B`).
It can be loaded from the assignment data directory as follows:

```{r load blocks}
load(path_concat(dataDirectory, "blocks.rda"))
head(blocks, n = 3)
```

In this question, you will investigate different sampling plans and estimation procedures.

\newpage

a. Simple random sampling.  

    i. *(4 marks)*  Collect the sample average block weight from each of 1000 samples, where each sample consists of 10 blocks selected at random (without replacement) from all 100 blocks. 
    
        Before sampling, `set.seed(314159)`
        
        Save the results on the \R variable `randomSampleAves`.  
    
        Show your code. 

    ii. *(3 marks)*  Using `randomSampleAves`, estimate the sampling bias, the sampling variability, and the sampling mean squared error of this sampling plan.
    
        Show your code. 

    iii. *(3 marks)*  Construct a (suitably labelled) histogram of the sample **errors** from this sampling plan.  
    
         Use `xlim = c(-20,20)`.  
        
         Add a vertical red dashed line of `lwd = 2` at the average error.
    
         Show your code. 
    
b. Stratified random sampling.  

    i. *(4 marks)*  Collect the sample average block weight from each of 1000 samples, where now each sample consists of 5 blocks selected at random (without replacement) from each of group "A" and group "B". 
    
        Before sampling, `set.seed(314159)`
        
        Save the results on the \R variable `stratifiedSampleAves`.  
    
        Show your code. 

    ii. *(3 marks)*  Using `stratifiedSampleAves`, estimate the sampling bias, the sampling variability, and the sampling mean squared error of this sampling plan.
    
        Show your code. 

    iii. *(3 marks)*  Construct a (suitably labelled) histogram of the sample **errors** from this sampling plan.  
    
         Use `xlim = c(-20,20)`.  
        
         Add a vertical red dashed line of `lwd = 2` at the average error.
    
         Show your code. 

c. Regression estimators.  In this question, we suppose that we know something about the population of blocks.  In particular, suppose we know that the average perimeter of all 100 blocks is `mean(blocks$perimeter) = ` `r mean(blocks$perimeter)`.  
    
    We also understand that there is some relationship between `perimeter` and `weight` in this population. 

    i. *(4 marks)*  Here 1,000 samples of 10  blocks are to be selected at random (without replacement) from all 100 blocks.  For each sample of 10 blocks, construct a straight line fit of the `weight` on `perimeter`.   Then use this fit to predict the mean weight of the population when the `perimeter` is the actual average perimeter of all 100 blocks.  Collect all 1,000 regression estimates.
    
        Before sampling, `set.seed(314159)`
        
        Save the results on the \R variable `regressionEstimates`.  
    
        Show your code. 

    ii. *(3 marks)*  Using `regressionEstimates`, estimate the sampling bias, the sampling variability, and the sampling mean squared error of this sampling plan.
    
        Show your code. 

    iii. *(3 marks)*  Construct a (suitably labelled) histogram of the sample **errors** from this sampling plan.  
    
         Use `xlim = c(-20,20)`.  
        
         Add a vertical red dashed line of `lwd = 2` at the average error.
    
         Show your code. 

    iv. *(2 marks)*  Is the straight line model used in this question "true"?  Is it useful?  Explain your answers.
    
        
d. A number of graduate data science students were asked to view the entire collection of 100 blocks and to choose 10 whose average weight they believed came close to matching that of all 100.  The sample units selected are recorded in another file, `judgmentSamples.csv`.  These can be loaded from the assignment data directory as follows:

    ```{r load students}
    students <- read.csv(path_concat(dataDirectory, "judgmentSamples.csv"))
    head(students, n = 3)
    ```
    
    There were a total of `r nrow(students)` students and hence  `r nrow(students)` samples selected.
    
    In this question, we compare the **judgment** sampling plan of the students with that of the random sampling plans considered above when only `r nrow(students)` samples of size 10 are selected.
    
    i. *(2 marks)* Gather together the average block weights of the student judgment samples.  
        Save the results on the \R variable `judgmentAves`.  
        
        Print the average of these averages.
    
        Show your code. 
    
    ii. *(8 marks)* Using `judgmentAves` and only the first `r nrow(students)` entries of each of `randomSampleAves`, `stratifiedSampleAves`, and `regressionEstimates`, construct four histograms one above the other (in the same display, use an appropriate `par()`) one for each of these sets of results.
    
        Make sure each histogram is labelled appropriately.
        
        Use the same `xlim = c(20, 50)`, `ylim = c(0, 15)`, and `breaks = seq(20, 50, 2)` for each histogram.
        
        On each histogram add a vertical red dashed line (with `lwd = 2`) at the true population average weight of all 100 blocks.
        
        On each histogram add a vertical "steelblue" **solid** line (with `lwd = 2`) at the average of all `r nrow(students)` sample estimates.
        
        On each histogram, add a legend indicating which vertical line is which.
        
        Show your code.
        

e. *(5 marks)* Comment on the relative merits of the four sampling plans.  Which would you most recomment? Which least?
